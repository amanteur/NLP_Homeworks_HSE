{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Homework1_Amatov_Amantur.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqamE7cRp1hZXWqYT1IFEF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtDpc075a1nP"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikEqpFITX69G"
      },
      "source": [
        "### Task 1\r\n",
        "\r\n",
        "Write a function which picks rhymes for a word using CMU Pronouncing Dictionary (nltk.corpus.cmudict). Two words usually rhyme if their pronunciation from the stressed syllable till the end of the word is the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uopw7LAQYZdi",
        "outputId": "96c72a3e-2bf7-476d-f8e4-dd6450202c04"
      },
      "source": [
        "from nltk.corpus import*\r\n",
        "nltk.download('cmudict')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46wBp8IJZMw3"
      },
      "source": [
        "def rhyme_grime(input_word='rhyme'):\r\n",
        "  '''\r\n",
        "  Returns set of rhymes for input word.\r\n",
        "  '''\r\n",
        "\r\n",
        "  if input_word not in cmudict.dict().keys():\r\n",
        "    raise ValueError('There is no such word in cmudict corpora.')\r\n",
        "\r\n",
        "  for pronoun in cmudict.dict()[input_word]:\r\n",
        "    pronunciation = pronoun\r\n",
        "    stressed_syl_idx = [idx for idx, syl in enumerate(pronunciation) if syl.endswith('1')][0]\r\n",
        "    rhyme_end = pronunciation[stressed_syl_idx:]\r\n",
        "    rhymes = []\r\n",
        "    for word, pronouns in cmudict.dict().items():\r\n",
        "      for pronoun in pronouns:\r\n",
        "        if pronoun[len(pronoun)-len(rhyme_end):] == rhyme_end:\r\n",
        "          rhymes.append(word)\r\n",
        "  rhymes.remove(input_word)\r\n",
        "\r\n",
        "  return set(rhymes)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCiCjePRk4xd"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmFD9USZk26S",
        "outputId": "27d930c4-4c68-42c4-d4f1-4938f7c25fe9"
      },
      "source": [
        "word = input(\"Enter word - \")\r\n",
        "print('There are {} rhymes to the word {}:\\n\\n{}'.format(len(rhyme_grime(word)), word, ',\\n'.join(rhyme_grime(word))))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter word - cloud\n",
            "There are 35 rhymes to the word cloud:\n",
            "\n",
            "houde,\n",
            "avowed,\n",
            "disavowed,\n",
            "plowed,\n",
            "how'd,\n",
            "loud,\n",
            "disallowed,\n",
            "o'dowd,\n",
            "crowd,\n",
            "odowd,\n",
            "vowed,\n",
            "wowed,\n",
            "stroud,\n",
            "browed,\n",
            "sowed,\n",
            "dowd,\n",
            "bowed,\n",
            "ploughed,\n",
            "doud,\n",
            "macleod,\n",
            "mcloud,\n",
            "cowed,\n",
            "endowed,\n",
            "aloud,\n",
            "abboud,\n",
            "goude,\n",
            "allowed,\n",
            "shroud,\n",
            "enshroud,\n",
            "mcleod,\n",
            "unbowed,\n",
            "overcrowd,\n",
            "daoud,\n",
            "proud,\n",
            "mccloud\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnrelWPIriVI"
      },
      "source": [
        "### Task 2\r\n",
        "Improve our text generator using trigrams (nltk.trigram) instead of bigrams. The idea is to select the next word based on two previous words, not just one. It is acceptable if you have to start the generation from two initial words instead of one. Apply the generator to texts from different corpora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brLiW8xhlf-k",
        "outputId": "3b9878b2-9bb1-4f9b-9589-7c2cae6aab56"
      },
      "source": [
        "nltk.download('webtext')\r\n",
        "nltk.download('inaugural')\r\n",
        "nltk.download('movie_reviews')\r\n",
        "nltk.download('brown')\r\n",
        "nltk.download('nps_chat')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPjtRTws5q6"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "def generate(corpora, word1=None, word2=None, sentences=5):\r\n",
        "  '''\r\n",
        "  Returns the generated text from trigrams built from input corpora.\r\n",
        "\r\n",
        "          Parameters:\r\n",
        "                  corpora: text from where trigrams will generate\r\n",
        "                  word1 (str): first conditional word from which text will be generated (default = None)\r\n",
        "                  word2 (str): second conditional word from which text will be generated (default = None)\r\n",
        "                  sentences (int): number of sentences in generated text (default = 5)\r\n",
        "\r\n",
        "          Returns:\r\n",
        "                  output_string (str): generated text\r\n",
        "  '''\r\n",
        "  \r\n",
        "  if (word1 == None and word2 != None) or (word2 == None and word1 != None):\r\n",
        "    raise ValueError('word1 and word2 must be specified together or not specified at all')\r\n",
        "\r\n",
        "  words = corpora.words()\r\n",
        "  trigrams = list(nltk.trigrams(words))\r\n",
        "  cfd = nltk.ConditionalFreqDist(((first,second),third)\r\n",
        "                                  for (first, second, third) in trigrams[:-2])\r\n",
        "  \r\n",
        "  if word1==None and word2==None:\r\n",
        "    word1, word2, _ = random.choice(trigrams)\r\n",
        "  \r\n",
        "  output_string = \"\"\r\n",
        "\r\n",
        "  while sentences > 0:\r\n",
        "    output_string += word2\r\n",
        "    if word2[0] in \".?!\":\r\n",
        "      sentences -= 1\r\n",
        "      output_string += '\\n'\r\n",
        "    else:\r\n",
        "      output_string += ' '\r\n",
        "\r\n",
        "    index = (word1, word2)\r\n",
        "    candidate_words = [word for word, freq in cfd[index].most_common()]\r\n",
        "    freqs = [freq for word, freq in cfd[index].most_common()]\r\n",
        "    word1 = word2\r\n",
        "    word2 = random.choices(candidate_words, weights = freqs)[0]\r\n",
        "\r\n",
        "  return output_string "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7qHKbxDRG-x"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIKPQCOl_ss",
        "outputId": "ce94685d-6e7f-4f87-8492-54fce9526087"
      },
      "source": [
        "# movie reviews\r\n",
        "corpora = movie_reviews\r\n",
        "word1 = 'based'\r\n",
        "word2 = 'on'\r\n",
        "\r\n",
        "print('Generated text based on words \\'{}\\' and \\'{}\\':\\n{}'.format(word1, word2, generate(corpora, word1, word2)))\r\n",
        "\r\n",
        "print('Generated text based on random 2 words:\\n{}'.format(generate(corpora)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated text based on words 'based' and 'on':\n",
            "on the straight - laced straight man .\n",
            "believe me when i saw this in the american political media works , due to all the plot has max asking his best here , her \" visions .\n",
            "because he couldn ' t happy !\n",
            "\" when we think .\n",
            "betty thomas worked wonders with it !\n",
            "\n",
            "Generated text based on random 2 words:\n",
            "named l .\n",
            "jackson ) , but the desert or astronauts in the us .\n",
            "president martin van buren ( nigel hawthorne do another voice for a heart operation .\n",
            "with a very rousing speech before sending his troops .\n",
            "the sound off .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2JYF0Yn3mX9",
        "outputId": "d4d9de4b-21ab-490d-c238-3edf212480df"
      },
      "source": [
        "# web text\r\n",
        "corpora = webtext\r\n",
        "print('Generated text based on random 2 words:\\n{}'.format(generate(corpora)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated text based on random 2 words:\n",
            ".\n",
            "** Apricot jam - quite hard and the station ?!\n",
            "Guy # 2 : The second smartest person in the right , we need a joint .\n",
            "A good wine for it , then you fart .\n",
            "Teen girl : Why do they have persuaded me that your phone stolen .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byqld6fU57_M",
        "outputId": "c89859db-a011-4827-b645-4f7e115e486d"
      },
      "source": [
        "# nps chat\r\n",
        "corpora = nps_chat\r\n",
        "print('Generated text based on random 2 words:\\n{}'.format(generate(corpora)))\r\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated text based on random 2 words:\n",
            "Whats going on U22 ...\n",
            "PART all the time PART will send the infor JOIN at what time U50 , as an elected official of this room LOL hey U104 !\n",
            "whip U50 heyyyy U110 U110 ??\n",
            "PART aww - thanks JOIN PART <333 whats up no offence against the gay JOIN 19 m fl !\n",
            "seen a girl or people have been lying to me dang it .......\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfv0Uj5n7PLK"
      },
      "source": [
        "### Task 3\r\n",
        "Write a code for Hangman game (https://en.wikipedia.org/wiki/Hangman_(game)). The code should select a random word from a dictionary (e. g. nltk.corpus.words) and show it to the user, replacing letters with dots. The user has to guess the word, naming one letter per move. If the named letter is there within the word, then all its occurrences are shown, otherwise the user loses an attempt. The user wins if (s)he opens all the letters before all attempts are spent, otherwise (s)he fails. You do not have to draw the hangman, just count the attempts left.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwgsvktQ7Lup"
      },
      "source": [
        "game_start = ''' _                                             \r\n",
        "| |                                            \r\n",
        "| |__   __ _ _ __   __ _ _ __ ___   __ _ _ __  \r\n",
        "| '_ \\ / _` | '_ \\ / _` | '_ ` _ \\ / _` | '_ \\ \r\n",
        "| | | | (_| | | | | (_| | | | | | | (_| | | | |\r\n",
        "|_| |_|\\__,_|_| |_|\\__, |_| |_| |_|\\__,_|_| |_|\r\n",
        "                    __/ |                      \r\n",
        "                   |___/                       '''\r\n",
        "hangman = ['''\r\n",
        "  +---+\r\n",
        "  |   |\r\n",
        "      |\r\n",
        "      |\r\n",
        "      |\r\n",
        "      |\r\n",
        "=========''', '''\r\n",
        "  +---+\r\n",
        "  |   |\r\n",
        "  O   |\r\n",
        "      |\r\n",
        "      |\r\n",
        "      |\r\n",
        "=========''', '''\r\n",
        "  +---+\r\n",
        "  |   |\r\n",
        "  O   |\r\n",
        "  |   |\r\n",
        "      |\r\n",
        "      |\r\n",
        "=========''', '''\r\n",
        "  +---+\r\n",
        "  |   |\r\n",
        "  O   |\r\n",
        " /|   |\r\n",
        "      |\r\n",
        "      |\r\n",
        "=========''', '''\r\n",
        "  +---+\r\n",
        "  |   |\r\n",
        "  O   |\r\n",
        " /|\\  |\r\n",
        "      |\r\n",
        "      |\r\n",
        "=========''', '''\r\n",
        "  +---+\r\n",
        "  |   |\r\n",
        "  O   |\r\n",
        " /|\\  |\r\n",
        " /    |\r\n",
        "      |\r\n",
        "=========''', '''\r\n",
        "  +---+\r\n",
        "  |   |\r\n",
        "  O   |\r\n",
        " /|\\  |\r\n",
        " / \\  |\r\n",
        "      |\r\n",
        "=========''']"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfAsFKSMa95A",
        "outputId": "33e7e2f9-a135-483c-9111-b51d6771ca90"
      },
      "source": [
        "nltk.download('popular')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AmXAllqY3Xl"
      },
      "source": [
        "from IPython.display import clear_output \r\n",
        "\r\n",
        "def hangman_word_gen(corpora, min_word_length=4, max_word_length = 10):\r\n",
        "  candidate_words = [word for word in corpora.words() if len(word) >= min_word_length and len(word) <= max_word_length\r\n",
        "                                                                                    and not word[0].isupper()]\r\n",
        "  random_word = random.choice(candidate_words)\r\n",
        "  return (list(random_word), list('*'*len(random_word)))\r\n",
        "\r\n",
        "def hangman_letter_check(guess_letter, guess_word):\r\n",
        "  letter_indexes = [i for i, ltr in enumerate(guess_word) if ltr == guess_letter]\r\n",
        "  if not letter_indexes:\r\n",
        "    return (False, [])\r\n",
        "  else:\r\n",
        "    return (True, letter_indexes)\r\n",
        "\r\n",
        "def hangman_game(corpora=words, min_word_length=4, max_word_length=10):\r\n",
        "\r\n",
        "  print(game_start)\r\n",
        "  newgame_input = input('Begin a new game? y/n\\n')\r\n",
        "  \r\n",
        "  if newgame_input == 'y':\r\n",
        "    clear_output()\r\n",
        "    print('Let\\'s begin!')\r\n",
        "    print(hangman[0])\r\n",
        "    guess_word, my_word = hangman_word_gen(corpora, min_word_length, max_word_length)\r\n",
        "    marker = True\r\n",
        "    hangman_iter = 0\r\n",
        "    guessed_letters = []\r\n",
        "    print(guess_word)\r\n",
        "\r\n",
        "    while marker:\r\n",
        "      print('Your word consists of {} letters:\\n{}'.format(len(guess_word), '-'.join(my_word)))\r\n",
        "      my_guess_letter = input('Your guess?\\n')\r\n",
        "      if len(my_guess_letter) > 1:\r\n",
        "        clear_output()\r\n",
        "        print(hangman[hangman_iter])\r\n",
        "        print('Use only letters!')\r\n",
        "        continue\r\n",
        "      marker = hangman_letter_check(my_guess_letter, guess_word)[0]\r\n",
        "\r\n",
        "      if not marker:\r\n",
        "        clear_output()\r\n",
        "        print(hangman[hangman_iter+1])\r\n",
        "        print('Oops, you got wrong')\r\n",
        "        hangman_iter += 1\r\n",
        "        if hangman_iter == 6:\r\n",
        "          print()\r\n",
        "          print(\"Hangman didn't discover that the real word was\", ''.join(guess_word))\r\n",
        "          return 'Game over'\r\n",
        "        else:\r\n",
        "          marker = True\r\n",
        "      elif marker and my_guess_letter not in guessed_letters:\r\n",
        "        clear_output()\r\n",
        "        print(hangman[hangman_iter])\r\n",
        "        print('Your\\'re right!')\r\n",
        "      elif marker and my_guess_letter in guessed_letters:\r\n",
        "        clear_output()\r\n",
        "        print(hangman[hangman_iter])\r\n",
        "        print('This letter is already used!')\r\n",
        "\r\n",
        "      guessed_letters.append(my_guess_letter)\r\n",
        "      print('Used letters:\\n', ' '.join(set(guessed_letters)))\r\n",
        "      positions = hangman_letter_check(my_guess_letter, guess_word)[1]\r\n",
        "      for pos in positions:\r\n",
        "        my_word[pos] = my_guess_letter\r\n",
        "      if '*' not in my_word:\r\n",
        "        print(\"Hangman discovered that the real word was\", ''.join(guess_word))\r\n",
        "        return 'You won!!!'\r\n",
        "\r\n",
        "  elif newgame_input == 'n':\r\n",
        "    return 'Game over'\r\n",
        "  else:\r\n",
        "    raise ValueError('Unknown symbol was passed.')"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "1ERCo1SuZ3UK",
        "outputId": "0993c5fb-2b1b-4f89-f894-317025eb049a"
      },
      "source": [
        "hangman_game(corpora=words, min_word_length=3, max_word_length=5)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  +---+\n",
            "  |   |\n",
            "  O   |\n",
            "      |\n",
            "      |\n",
            "      |\n",
            "=========\n",
            "Your're right!\n",
            "Used letters:\n",
            " w a i t l\n",
            "Hangman discovered that the real word was twill\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You won!!!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    }
  ]
}